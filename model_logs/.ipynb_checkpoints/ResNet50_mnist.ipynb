{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQT7aPgd5jGl",
        "outputId": "17ede3fd-d484-40b5-e7b5-81b789180eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZxrO6Oi5sqR",
        "outputId": "8eb643c1-406e-4b19-eb92-a83b6a2f906e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kgAd3t853GD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import time\n",
        "import os.path as osp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn_S9FIh6PsR"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(28, padding=4),  # MNIST images are 28x28\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize for single-channel images\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data_mnist', train=True, download=True, transform=train_transform)\n",
        "test_dataset = datasets.MNIST(root='./data_mnist', train=False, download=True, transform=test_transform)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeDzjcS26Vor",
        "outputId": "e64d2e59-c36e-4d95-f999-7900c3cacd05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "resnet50 = models.resnet50(pretrained=False)\n",
        "num_classes = 10\n",
        "resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "in_features = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr7r0QPv6duI",
        "outputId": "d570492c-4243-4b55-8a7e-43941a015488"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet50.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet50.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcX1kRysmmdz"
      },
      "outputs": [],
      "source": [
        "log_file_path = \"/content/gdrive/MyDrive/Project_II/model_logging/resnet_50_mnist.log\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdoVoHH-6pRl"
      },
      "outputs": [],
      "source": [
        "# definition a function to write data to log file\n",
        "def write_log(log_file_path, content):\n",
        "    with open(log_file_path, 'a') as log_file:\n",
        "        log_file.write(content + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB2EszyXiy9H"
      },
      "outputs": [],
      "source": [
        "# definition a function to read data from log file\n",
        "def read_log(log_file_path):\n",
        "    with open(log_file_path, 'r') as log_file:\n",
        "        lines = log_file.readlines()\n",
        "\n",
        "    # Check if log file contains data or being empty\n",
        "    if len(lines) == 0:\n",
        "        return 0, None\n",
        "\n",
        "    # Get the number of epochs has been completed\n",
        "    num_epochs_completed = len(lines) // 3\n",
        "\n",
        "    # Checking in the log file if the remaining number of epochs still acceptable\n",
        "    if len(lines) < 3 or len(lines) % 3 != 0:\n",
        "        print(\"Error: File log contains incomplete or invalid information.\")\n",
        "        return num_epochs_completed, None\n",
        "\n",
        "    try:\n",
        "        # Get the information of the last epoch\n",
        "        last_epoch_info = lines[-3:]\n",
        "        last_epoch_train_loss = float(last_epoch_info[0].split(\":\")[1].strip())\n",
        "        last_epoch_train_accuracy = float(last_epoch_info[1].split(\":\")[1].strip()[:-1])\n",
        "    except (ValueError, IndexError) as e:\n",
        "        print(\"Error: Invalid format or missing information in log file.\")\n",
        "        return num_epochs_completed, None\n",
        "\n",
        "    return num_epochs_completed, (last_epoch_train_loss, last_epoch_train_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IWe9ZQWkEv8"
      },
      "outputs": [],
      "source": [
        "# Intialize the array to save training time per each epoch\n",
        "epoch_times_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gv6FQ-_rqjJB"
      },
      "outputs": [],
      "source": [
        "# Starting to calculate training model time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDAmuuRz6kWR"
      },
      "outputs": [],
      "source": [
        "# Training model per each epoch\n",
        "def train(epoch):\n",
        "    resnet50.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_time_str = f\"{int(elapsed_time // 60)}m {int(elapsed_time % 60)}s\"\n",
        "    write_log(log_file_path, f\"Training Loss: {train_loss / len(train_loader):.3f} \\t\\t Training Accuracy: {100 * correct / total:.2f}%\")\n",
        "    write_log(log_file_path, f\"\\tElapsed Time: {elapsed_time_str}\")\n",
        "\n",
        "    # Updating total running time of all epochs\n",
        "    total_elapsed_time = sum([epoch_times[1] for epoch_times in epoch_times_list])\n",
        "    total_elapsed_time_str = f\"{int(total_elapsed_time // 3600)}h {int((total_elapsed_time % 3600) // 60)}m {int(total_elapsed_time % 60)}s\"\n",
        "    write_log(log_file_path, f\"\\tTotal Elapsed Time: {total_elapsed_time_str}\\n{'-'*50}\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1}:\\nTraining Loss: {train_loss / len(train_loader):.3f}, Accuracy: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFcv0Q7VlSje"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "    resnet50.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = resnet50(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    write_log(log_file_path, f\"ResNet-50\\n{'-'*50}\\nEpoch {epoch+1}:\\nTest Loss: {avg_loss:.3f} \\t\\t Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"ResNet-50\\n{'-'*50}\\nEpoch {epoch+1}:\\nTest Loss: {avg_loss:.3f}, Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Inv_aq7mRO"
      },
      "outputs": [],
      "source": [
        "# Moving the model to device\n",
        "num_epochs = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet50.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f_QWgrRk47H",
        "outputId": "da6f102c-9e13-4c47-f128-3473dc02dfe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 1:\n",
            "Test Loss: 0.089, Accuracy: 97.07%\n",
            "Epoch 1:\n",
            "Training Loss: 0.125, Accuracy: 96.03%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 2:\n",
            "Test Loss: 0.074, Accuracy: 97.53%\n",
            "Epoch 2:\n",
            "Training Loss: 0.112, Accuracy: 96.53%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 3:\n",
            "Test Loss: 0.078, Accuracy: 97.46%\n",
            "Epoch 3:\n",
            "Training Loss: 0.094, Accuracy: 96.98%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 4:\n",
            "Test Loss: 0.060, Accuracy: 98.04%\n",
            "Epoch 4:\n",
            "Training Loss: 0.083, Accuracy: 97.36%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 5:\n",
            "Test Loss: 0.056, Accuracy: 98.28%\n",
            "Epoch 5:\n",
            "Training Loss: 0.075, Accuracy: 97.61%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 6:\n",
            "Test Loss: 0.042, Accuracy: 98.50%\n",
            "Epoch 6:\n",
            "Training Loss: 0.069, Accuracy: 97.83%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 7:\n",
            "Test Loss: 0.043, Accuracy: 98.62%\n",
            "Epoch 7:\n",
            "Training Loss: 0.065, Accuracy: 97.93%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 8:\n",
            "Test Loss: 0.041, Accuracy: 98.72%\n",
            "Epoch 8:\n",
            "Training Loss: 0.058, Accuracy: 98.25%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 9:\n",
            "Test Loss: 0.035, Accuracy: 98.83%\n",
            "Epoch 9:\n",
            "Training Loss: 0.058, Accuracy: 98.25%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 10:\n",
            "Test Loss: 0.037, Accuracy: 98.86%\n",
            "Epoch 10:\n",
            "Training Loss: 0.053, Accuracy: 98.37%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 11:\n",
            "Test Loss: 0.034, Accuracy: 98.94%\n",
            "Epoch 11:\n",
            "Training Loss: 0.051, Accuracy: 98.37%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 12:\n",
            "Test Loss: 0.035, Accuracy: 98.92%\n",
            "Epoch 12:\n",
            "Training Loss: 0.048, Accuracy: 98.49%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 13:\n",
            "Test Loss: 0.032, Accuracy: 99.00%\n",
            "Epoch 13:\n",
            "Training Loss: 0.045, Accuracy: 98.59%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 14:\n",
            "Test Loss: 0.031, Accuracy: 99.03%\n",
            "Epoch 14:\n",
            "Training Loss: 0.045, Accuracy: 98.62%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 15:\n",
            "Test Loss: 0.031, Accuracy: 99.09%\n",
            "Epoch 15:\n",
            "Training Loss: 0.064, Accuracy: 98.21%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 16:\n",
            "Test Loss: 0.155, Accuracy: 97.15%\n",
            "Epoch 16:\n",
            "Training Loss: 0.063, Accuracy: 98.12%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 17:\n",
            "Test Loss: 0.030, Accuracy: 98.84%\n",
            "Epoch 17:\n",
            "Training Loss: 0.050, Accuracy: 98.48%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 18:\n",
            "Test Loss: 0.030, Accuracy: 99.07%\n",
            "Epoch 18:\n",
            "Training Loss: 0.042, Accuracy: 98.66%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 19:\n",
            "Test Loss: 0.034, Accuracy: 98.91%\n",
            "Epoch 19:\n",
            "Training Loss: 0.039, Accuracy: 98.80%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 20:\n",
            "Test Loss: 0.025, Accuracy: 99.18%\n",
            "Epoch 20:\n",
            "Training Loss: 0.036, Accuracy: 98.90%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 21:\n",
            "Test Loss: 0.029, Accuracy: 99.17%\n",
            "Epoch 21:\n",
            "Training Loss: 0.034, Accuracy: 98.93%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 22:\n",
            "Test Loss: 0.024, Accuracy: 99.20%\n",
            "Epoch 22:\n",
            "Training Loss: 0.033, Accuracy: 98.98%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 23:\n",
            "Test Loss: 0.027, Accuracy: 99.16%\n",
            "Epoch 23:\n",
            "Training Loss: 0.039, Accuracy: 98.80%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 24:\n",
            "Test Loss: 0.028, Accuracy: 99.07%\n",
            "Epoch 24:\n",
            "Training Loss: 0.033, Accuracy: 98.94%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 25:\n",
            "Test Loss: 0.020, Accuracy: 99.30%\n",
            "Epoch 25:\n",
            "Training Loss: 0.032, Accuracy: 98.98%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 26:\n",
            "Test Loss: 0.023, Accuracy: 99.25%\n",
            "Epoch 26:\n",
            "Training Loss: 0.032, Accuracy: 99.03%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 27:\n",
            "Test Loss: 0.024, Accuracy: 99.19%\n",
            "Epoch 27:\n",
            "Training Loss: 0.031, Accuracy: 99.00%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 28:\n",
            "Test Loss: 0.022, Accuracy: 99.29%\n",
            "Epoch 28:\n",
            "Training Loss: 0.019, Accuracy: 99.42%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 29:\n",
            "Test Loss: 0.016, Accuracy: 99.44%\n",
            "Epoch 29:\n",
            "Training Loss: 0.015, Accuracy: 99.50%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 30:\n",
            "Test Loss: 0.014, Accuracy: 99.52%\n",
            "Epoch 30:\n",
            "Training Loss: 0.015, Accuracy: 99.54%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 31:\n",
            "Test Loss: 0.014, Accuracy: 99.50%\n",
            "Epoch 31:\n",
            "Training Loss: 0.014, Accuracy: 99.58%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 32:\n",
            "Test Loss: 0.016, Accuracy: 99.40%\n",
            "Epoch 32:\n",
            "Training Loss: 0.013, Accuracy: 99.61%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 33:\n",
            "Test Loss: 0.015, Accuracy: 99.50%\n",
            "Epoch 33:\n",
            "Training Loss: 0.012, Accuracy: 99.67%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 34:\n",
            "Test Loss: 0.013, Accuracy: 99.53%\n",
            "Epoch 34:\n",
            "Training Loss: 0.012, Accuracy: 99.65%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 35:\n",
            "Test Loss: 0.013, Accuracy: 99.56%\n",
            "Epoch 35:\n",
            "Training Loss: 0.011, Accuracy: 99.64%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 36:\n",
            "Test Loss: 0.014, Accuracy: 99.51%\n",
            "Epoch 36:\n",
            "Training Loss: 0.011, Accuracy: 99.64%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 37:\n",
            "Test Loss: 0.014, Accuracy: 99.55%\n",
            "Epoch 37:\n",
            "Training Loss: 0.010, Accuracy: 99.67%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 38:\n",
            "Test Loss: 0.013, Accuracy: 99.55%\n",
            "Epoch 38:\n",
            "Training Loss: 0.010, Accuracy: 99.67%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 39:\n",
            "Test Loss: 0.014, Accuracy: 99.54%\n",
            "Epoch 39:\n",
            "Training Loss: 0.010, Accuracy: 99.69%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 40:\n",
            "Test Loss: 0.014, Accuracy: 99.56%\n",
            "Epoch 40:\n",
            "Training Loss: 0.009, Accuracy: 99.70%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 41:\n",
            "Test Loss: 0.012, Accuracy: 99.57%\n",
            "Epoch 41:\n",
            "Training Loss: 0.008, Accuracy: 99.75%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 42:\n",
            "Test Loss: 0.013, Accuracy: 99.57%\n",
            "Epoch 42:\n",
            "Training Loss: 0.009, Accuracy: 99.71%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 43:\n",
            "Test Loss: 0.013, Accuracy: 99.54%\n",
            "Epoch 43:\n",
            "Training Loss: 0.009, Accuracy: 99.72%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 44:\n",
            "Test Loss: 0.013, Accuracy: 99.58%\n",
            "Epoch 44:\n",
            "Training Loss: 0.008, Accuracy: 99.74%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 45:\n",
            "Test Loss: 0.012, Accuracy: 99.56%\n",
            "Epoch 45:\n",
            "Training Loss: 0.009, Accuracy: 99.71%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 46:\n",
            "Test Loss: 0.013, Accuracy: 99.55%\n",
            "Epoch 46:\n",
            "Training Loss: 0.008, Accuracy: 99.73%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 47:\n",
            "Test Loss: 0.013, Accuracy: 99.49%\n",
            "Epoch 47:\n",
            "Training Loss: 0.008, Accuracy: 99.75%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 48:\n",
            "Test Loss: 0.013, Accuracy: 99.54%\n",
            "Epoch 48:\n",
            "Training Loss: 0.007, Accuracy: 99.77%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 49:\n",
            "Test Loss: 0.013, Accuracy: 99.54%\n",
            "Epoch 49:\n",
            "Training Loss: 0.008, Accuracy: 99.75%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 50:\n",
            "Test Loss: 0.013, Accuracy: 99.54%\n",
            "Epoch 50:\n",
            "Training Loss: 0.008, Accuracy: 99.72%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 51:\n",
            "Test Loss: 0.014, Accuracy: 99.48%\n",
            "Epoch 51:\n",
            "Training Loss: 0.007, Accuracy: 99.79%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 52:\n",
            "Test Loss: 0.013, Accuracy: 99.53%\n",
            "Epoch 52:\n",
            "Training Loss: 0.008, Accuracy: 99.75%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 53:\n",
            "Test Loss: 0.015, Accuracy: 99.47%\n",
            "Epoch 53:\n",
            "Training Loss: 0.006, Accuracy: 99.79%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 54:\n",
            "Test Loss: 0.014, Accuracy: 99.47%\n",
            "Epoch 54:\n",
            "Training Loss: 0.007, Accuracy: 99.78%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 55:\n",
            "Test Loss: 0.013, Accuracy: 99.55%\n",
            "Epoch 55:\n",
            "Training Loss: 0.007, Accuracy: 99.76%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 56:\n",
            "Test Loss: 0.013, Accuracy: 99.54%\n",
            "Epoch 56:\n",
            "Training Loss: 0.007, Accuracy: 99.80%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 57:\n",
            "Test Loss: 0.016, Accuracy: 99.47%\n",
            "Epoch 57:\n",
            "Training Loss: 0.007, Accuracy: 99.79%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 58:\n",
            "Test Loss: 0.014, Accuracy: 99.55%\n",
            "Epoch 58:\n",
            "Training Loss: 0.005, Accuracy: 99.85%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 59:\n",
            "Test Loss: 0.013, Accuracy: 99.61%\n",
            "Epoch 59:\n",
            "Training Loss: 0.005, Accuracy: 99.86%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 60:\n",
            "Test Loss: 0.013, Accuracy: 99.59%\n",
            "Epoch 60:\n",
            "Training Loss: 0.005, Accuracy: 99.86%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 61:\n",
            "Test Loss: 0.013, Accuracy: 99.59%\n",
            "Epoch 61:\n",
            "Training Loss: 0.004, Accuracy: 99.86%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 62:\n",
            "Test Loss: 0.013, Accuracy: 99.56%\n",
            "Epoch 62:\n",
            "Training Loss: 0.005, Accuracy: 99.86%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 63:\n",
            "Test Loss: 0.013, Accuracy: 99.61%\n",
            "Epoch 63:\n",
            "Training Loss: 0.004, Accuracy: 99.86%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 64:\n",
            "Test Loss: 0.013, Accuracy: 99.58%\n",
            "Epoch 64:\n",
            "Training Loss: 0.005, Accuracy: 99.87%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 65:\n",
            "Test Loss: 0.013, Accuracy: 99.57%\n",
            "Epoch 65:\n",
            "Training Loss: 0.005, Accuracy: 99.85%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 66:\n",
            "Test Loss: 0.013, Accuracy: 99.59%\n",
            "Epoch 66:\n",
            "Training Loss: 0.005, Accuracy: 99.86%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 67:\n",
            "Test Loss: 0.013, Accuracy: 99.56%\n",
            "Epoch 67:\n",
            "Training Loss: 0.004, Accuracy: 99.87%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 68:\n",
            "Test Loss: 0.014, Accuracy: 99.57%\n",
            "Epoch 68:\n",
            "Training Loss: 0.004, Accuracy: 99.88%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 69:\n",
            "Test Loss: 0.013, Accuracy: 99.58%\n",
            "Epoch 69:\n",
            "Training Loss: 0.004, Accuracy: 99.88%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 70:\n",
            "Test Loss: 0.013, Accuracy: 99.59%\n",
            "Epoch 70:\n",
            "Training Loss: 0.004, Accuracy: 99.86%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 71:\n",
            "Test Loss: 0.013, Accuracy: 99.56%\n",
            "Epoch 71:\n",
            "Training Loss: 0.004, Accuracy: 99.87%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 72:\n",
            "Test Loss: 0.013, Accuracy: 99.58%\n",
            "Epoch 72:\n",
            "Training Loss: 0.004, Accuracy: 99.86%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 73:\n",
            "Test Loss: 0.013, Accuracy: 99.57%\n",
            "Epoch 73:\n",
            "Training Loss: 0.004, Accuracy: 99.88%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 74:\n",
            "Test Loss: 0.014, Accuracy: 99.55%\n",
            "Epoch 74:\n",
            "Training Loss: 0.005, Accuracy: 99.86%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 75:\n",
            "Test Loss: 0.014, Accuracy: 99.54%\n",
            "Epoch 75:\n",
            "Training Loss: 0.004, Accuracy: 99.86%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 76:\n",
            "Test Loss: 0.013, Accuracy: 99.57%\n",
            "Epoch 76:\n",
            "Training Loss: 0.004, Accuracy: 99.89%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 77:\n",
            "Test Loss: 0.013, Accuracy: 99.58%\n",
            "Epoch 77:\n",
            "Training Loss: 0.004, Accuracy: 99.88%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 78:\n",
            "Test Loss: 0.014, Accuracy: 99.57%\n",
            "Epoch 78:\n",
            "Training Loss: 0.004, Accuracy: 99.88%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 79:\n",
            "Test Loss: 0.013, Accuracy: 99.60%\n",
            "Epoch 79:\n",
            "Training Loss: 0.004, Accuracy: 99.87%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 80:\n",
            "Test Loss: 0.013, Accuracy: 99.62%\n",
            "Epoch 80:\n",
            "Training Loss: 0.004, Accuracy: 99.90%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 81:\n",
            "Test Loss: 0.014, Accuracy: 99.57%\n",
            "Epoch 81:\n",
            "Training Loss: 0.004, Accuracy: 99.88%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 82:\n",
            "Test Loss: 0.013, Accuracy: 99.59%\n",
            "Epoch 82:\n",
            "Training Loss: 0.004, Accuracy: 99.85%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 83:\n",
            "Test Loss: 0.014, Accuracy: 99.57%\n",
            "Epoch 83:\n",
            "Training Loss: 0.004, Accuracy: 99.87%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 84:\n",
            "Test Loss: 0.014, Accuracy: 99.57%\n",
            "Epoch 84:\n",
            "Training Loss: 0.004, Accuracy: 99.90%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 85:\n",
            "Test Loss: 0.013, Accuracy: 99.55%\n",
            "Epoch 85:\n",
            "Training Loss: 0.004, Accuracy: 99.90%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 86:\n",
            "Test Loss: 0.013, Accuracy: 99.55%\n",
            "Epoch 86:\n",
            "Training Loss: 0.004, Accuracy: 99.89%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 87:\n",
            "Test Loss: 0.013, Accuracy: 99.61%\n",
            "Epoch 87:\n",
            "Training Loss: 0.004, Accuracy: 99.87%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 88:\n",
            "Test Loss: 0.014, Accuracy: 99.56%\n",
            "Epoch 88:\n",
            "Training Loss: 0.003, Accuracy: 99.91%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 89:\n",
            "Test Loss: 0.014, Accuracy: 99.57%\n",
            "Epoch 89:\n",
            "Training Loss: 0.003, Accuracy: 99.89%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 90:\n",
            "Test Loss: 0.014, Accuracy: 99.55%\n",
            "Epoch 90:\n",
            "Training Loss: 0.004, Accuracy: 99.89%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 91:\n",
            "Test Loss: 0.013, Accuracy: 99.55%\n",
            "Epoch 91:\n",
            "Training Loss: 0.003, Accuracy: 99.90%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 92:\n",
            "Test Loss: 0.013, Accuracy: 99.62%\n",
            "Epoch 92:\n",
            "Training Loss: 0.003, Accuracy: 99.90%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 93:\n",
            "Test Loss: 0.013, Accuracy: 99.60%\n",
            "Epoch 93:\n",
            "Training Loss: 0.003, Accuracy: 99.90%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 94:\n",
            "Test Loss: 0.014, Accuracy: 99.59%\n",
            "Epoch 94:\n",
            "Training Loss: 0.003, Accuracy: 99.90%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 95:\n",
            "Test Loss: 0.013, Accuracy: 99.59%\n",
            "Epoch 95:\n",
            "Training Loss: 0.003, Accuracy: 99.90%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 96:\n",
            "Test Loss: 0.013, Accuracy: 99.57%\n",
            "Epoch 96:\n",
            "Training Loss: 0.004, Accuracy: 99.88%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 97:\n",
            "Test Loss: 0.013, Accuracy: 99.58%\n",
            "Epoch 97:\n",
            "Training Loss: 0.004, Accuracy: 99.89%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 98:\n",
            "Test Loss: 0.013, Accuracy: 99.57%\n",
            "Epoch 98:\n",
            "Training Loss: 0.004, Accuracy: 99.87%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 99:\n",
            "Test Loss: 0.013, Accuracy: 99.57%\n",
            "Epoch 99:\n",
            "Training Loss: 0.004, Accuracy: 99.89%\n",
            "ResNet-50\n",
            "--------------------------------------------------\n",
            "Epoch 100:\n",
            "Test Loss: 0.014, Accuracy: 99.55%\n",
            "Epoch 100:\n",
            "Training Loss: 0.003, Accuracy: 99.91%\n"
          ]
        }
      ],
      "source": [
        "# Read data from the last epoch\n",
        "num_epochs_completed, last_epoch_info = read_log(log_file_path)\n",
        "start_epoch = num_epochs_completed\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    test()\n",
        "    train(epoch)\n",
        "    scheduler.step()\n",
        "\n",
        "    # Saving model\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    epoch_times_list.append((epoch + 1, elapsed_time))\n",
        "\n",
        "    torch.save(resnet50.state_dict(), \"/content/gdrive/MyDrive/Project_II/model_logging/resnet50_cifar10_model.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
