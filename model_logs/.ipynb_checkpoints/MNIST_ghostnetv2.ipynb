{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QngvCPoqS5TJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os.path as osp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtcvAvmITj7V",
        "outputId": "092c7ae0-70f9-47b1-8957-a1c58ffd0711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKruJrkvTn0-"
      },
      "outputs": [],
      "source": [
        "# Definite GhostModule class\n",
        "class GhostModule(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels, kernel_size=1, ratio=2):\n",
        "        super(GhostModule, self).__init__()\n",
        "        self.primary_conv = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, output_channels // ratio, kernel_size, bias=False),\n",
        "            nn.BatchNorm2d(output_channels // ratio),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.cheap_operation = nn.Sequential(\n",
        "            nn.Conv2d(output_channels // ratio, output_channels, kernel_size, groups=output_channels // ratio, bias=False),\n",
        "            nn.BatchNorm2d(output_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.primary_conv(x)  # The first GhostModule block\n",
        "        x2 = self.cheap_operation(x1)  # The second GhostModule block\n",
        "        out = torch.cat([x1, x2], dim=1)\n",
        "        return out[:, :x.shape[1], :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c4zXcRMTpft"
      },
      "outputs": [],
      "source": [
        "class SELayer(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu380N-rTrAU"
      },
      "outputs": [],
      "source": [
        "class GhostBottleneck(nn.Module):\n",
        "    def __init__(self, input_channels, hidden_channels, output_channels, kernel_size, stride, use_se=True):\n",
        "        super(GhostBottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, hidden_channels, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
        "        self.ghost = GhostModule(hidden_channels, hidden_channels, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(hidden_channels, output_channels, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.stride = stride\n",
        "        self.use_se = use_se\n",
        "\n",
        "        if self.use_se:\n",
        "            self.se = SELayer(output_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.ghost(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.use_se:\n",
        "            out = self.se(out)\n",
        "\n",
        "        if self.stride == 1 and identity.shape[1] == out.shape[1]:\n",
        "            identity = nn.functional.interpolate(identity, size=out.shape[2:], mode='nearest')\n",
        "            out += identity\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyP44bd0TsZn"
      },
      "outputs": [],
      "source": [
        "class GhostNetV2(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(GhostNetV2, self).__init__()\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=1, padding=1, bias=False),  # Change the input channel to 1 (grayscale)\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.stage1 = self._make_stage(16, 16, 1, stride=1)\n",
        "        self.stage2 = self._make_stage(16, 24, 2, stride=2)\n",
        "        self.stage3 = self._make_stage(24, 40, 3, stride=2, use_se=True)  # Using SE layer\n",
        "        self.stage4 = self._make_stage(40, 80, 3, stride=2, use_se=True)\n",
        "        self.stage5 = self._make_stage(80, 96, 2, stride=1, use_se=True)\n",
        "        self.stage6 = self._make_stage(96, 192, 4, stride=2, use_se=True)\n",
        "        self.stage7 = self._make_stage(192, 320, 1, stride=1, use_se=True)\n",
        "\n",
        "        self.conv9 = nn.Sequential(\n",
        "            nn.Conv2d(320, 1280, 1, bias=False),\n",
        "            nn.BatchNorm2d(1280),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(1280, num_classes)\n",
        "\n",
        "    def _make_stage(self, input_channels, output_channels, num_blocks, stride, use_se=False):  # Add use_se parameter\n",
        "        layers = []\n",
        "        layers.append(GhostBottleneck(input_channels, input_channels // 2, output_channels, 3, stride, use_se))  # Using SE layer in GhostBottleneck\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(GhostBottleneck(output_channels, output_channels // 2, output_channels, 3, 1, use_se))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stem(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.stage5(out)\n",
        "        out = self.stage6(out)\n",
        "        out = self.stage7(out)\n",
        "        out = self.conv9(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POdqwAZkT5JF"
      },
      "outputs": [],
      "source": [
        "# Adjust the number of classes to 10 for MNIST\n",
        "ghostnet = GhostNetV2(num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "784z5MygUC3I"
      },
      "outputs": [],
      "source": [
        "# Write data into the log file\n",
        "def write_log(log_file_path, content):\n",
        "    with open(log_file_path, 'a') as log_file:\n",
        "        log_file.write(content + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1MWjJQL-L8k"
      },
      "outputs": [],
      "source": [
        "# Create read_log function to read data from the log file:\n",
        "def read_log(log_file_path):\n",
        "    with open(log_file_path, 'r') as log_file:\n",
        "        lines = log_file.readlines()\n",
        "\n",
        "    # Checking if file log contains data\n",
        "    if len(lines) == 0:\n",
        "        return 0, None\n",
        "\n",
        "    # Get the number of epochs has been completed\n",
        "    num_epochs_completed = len(lines) // 4\n",
        "\n",
        "    # Checking in the log file if the remaining number of epochs still acceptable \n",
        "    if len(lines) < 3 or len(lines) % 3 != 0:\n",
        "        print(\"Error: File log contains incomplete or invalid information.\")\n",
        "        return num_epochs_completed, None\n",
        "\n",
        "    try:\n",
        "        # Get the information of the last epoch\n",
        "        last_epoch_info = lines[-5:]\n",
        "        last_epoch_train_loss = float(last_epoch_info[0].split(\":\")[1].strip())\n",
        "        last_epoch_train_accuracy = float(last_epoch_info[1].split(\":\")[1].strip()[:-1])\n",
        "    except (ValueError, IndexError) as e:\n",
        "        print(\"Error: Invalid format or missing information in log file.\")\n",
        "        return num_epochs_completed, None\n",
        "\n",
        "    return num_epochs_completed, (last_epoch_train_loss, last_epoch_train_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZXJxi88T6VI"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(28, padding=4),  # MNIST images are 28x28\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize for single-channel images\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(28, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(root='./data_mnist', train=True, download=True, transform=train_transform)\n",
        "test_dataset = MNIST(root='./data_mnist', train=False, download=True, transform=test_transform)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kqMELobUBhj"
      },
      "outputs": [],
      "source": [
        "# Definite loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(ghostnet.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVUag_EU3oLf"
      },
      "outputs": [],
      "source": [
        "# Intialize the array to save training time per each epoch\n",
        "epoch_times_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WVbs-m-3pqW"
      },
      "outputs": [],
      "source": [
        "# Starting to calculate training model time\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4iJMaKksiZu"
      },
      "outputs": [],
      "source": [
        "def train_model(num_epochs, ghostnet, train_loader, test_loader, criterion, optimizer, device, log_file_path):\n",
        "    # Read the data from the log file\n",
        "    num_epochs_completed, last_epoch_info = read_log(log_file_path)\n",
        "\n",
        "    # start_epoch is recorded from the last training turn, if there is the first training turn so num_epochs_completed = 0\n",
        "    start_epoch = num_epochs_completed + 1\n",
        "\n",
        "    # Adding information of last epoch\n",
        "    if last_epoch_info:\n",
        "        last_epoch_train_loss, last_epoch_train_accuracy, last_epoch_test_loss, last_epoch_test_accuracy = last_epoch_info\n",
        "        write_log(log_file_path, f\"GhostNet V2\\n{'-'*50}\\nEpoch {num_epochs_completed + 1}:\\n\\tTrain loss: {last_epoch_train_loss:.3f}, Train Accuracy: {last_epoch_train_accuracy:.2f}%\")\n",
        "        write_log(log_file_path, f\"\\tTest Loss: {last_epoch_test_loss:.3f}, Test Accuracy: {last_epoch_test_accuracy:.2f}%\")\n",
        "        write_log(log_file_path, f\"\\tElapsed Time: {elapsed_time_str}\")\n",
        "\n",
        "    # Initialize total elapsed time\n",
        "    total_elapsed_time = 0\n",
        "\n",
        "    # Start time for training process\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Training model from the last epoch.\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        # Start time for current epoch\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        # Training model for training dataset\n",
        "        ghostnet.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = ghostnet(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Updating the total loss and number of correct predictions\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Evaluate mode for testing dataset\n",
        "        ghostnet.eval()\n",
        "        test_loss = 0.0\n",
        "        test_correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = ghostnet(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                test_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate and print the result\n",
        "        train_loss = train_loss / len(train_dataset)\n",
        "        train_accuracy = train_correct / len(train_dataset) * 100\n",
        "        test_loss = test_loss / len(test_dataset)\n",
        "        test_accuracy = test_correct / len(test_dataset) * 100\n",
        "\n",
        "        # Saving model\n",
        "        torch.save(ghostnet.state_dict(), \"ghostnetv2_mnist_model.pth\")\n",
        "\n",
        "        # Write the results to log file\n",
        "        write_log(log_file_path, f\"GhostNet V2\\n{'-'*50}\\nEpoch {epoch+1}:\\n\\tLoss: {train_loss:.3f}, Accuracy: {train_accuracy:.2f}%\")\n",
        "        write_log(log_file_path, f\"\\tTest Loss: {train_loss:.3f}, Test Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - epoch_start_time\n",
        "        elapsed_time_str = f\"{int(elapsed_time // 3600)}h {int((elapsed_time % 3600) // 60)}m {int(elapsed_time % 60)}s\"\n",
        "        epoch_times_list.append((epoch + 1, elapsed_time))\n",
        "\n",
        "        # Calculate total elapsed time\n",
        "        total_elapsed_time = sum([epoch_times[1] for epoch_times in epoch_times_list])\n",
        "        total_elapsed_time_str = f\"{int(total_elapsed_time // 3600)}h {int((total_elapsed_time % 3600) // 60)}m {int(total_elapsed_time % 60)}s\"\n",
        "        write_log(log_file_path, f\"\\tElapsed Time: {elapsed_time_str}\")\n",
        "        write_log(log_file_path, f\"\\tTotal Elapsed Time: {total_elapsed_time_str}\\n{'-'*50}\")\n",
        "\n",
        "        print(f\"GhostNet V2\\n{'-'*50}\\nEpoch {epoch+1}:\\n\\tLoss: {train_loss:.3f}, Accuracy: {train_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJHjC-K8-gmg",
        "outputId": "a6e6be6a-3ae1-4e70-b0fa-5ffe2b6c5055"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GhostNetV2(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (stage1): Sequential(\n",
              "    (0): GhostBottleneck(\n",
              "      (conv1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(4, 8, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "          (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage2): Sequential(\n",
              "    (0): GhostBottleneck(\n",
              "      (conv1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(4, 8, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
              "          (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(8, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): GhostBottleneck(\n",
              "      (conv1): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(12, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(6, 12, kernel_size=(1, 1), stride=(1, 1), groups=6, bias=False)\n",
              "          (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage3): Sequential(\n",
              "    (0): GhostBottleneck(\n",
              "      (conv1): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(12, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(6, 12, kernel_size=(1, 1), stride=(1, 1), groups=6, bias=False)\n",
              "          (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(12, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=40, out_features=2, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=2, out_features=40, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): GhostBottleneck(\n",
              "      (conv1): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(10, 20, kernel_size=(1, 1), stride=(1, 1), groups=10, bias=False)\n",
              "          (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(20, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=40, out_features=2, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=2, out_features=40, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): GhostBottleneck(\n",
              "      (conv1): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(10, 20, kernel_size=(1, 1), stride=(1, 1), groups=10, bias=False)\n",
              "          (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(20, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=40, out_features=2, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=2, out_features=40, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage4): Sequential(\n",
              "    (0): GhostBottleneck(\n",
              "      (conv1): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(10, 20, kernel_size=(1, 1), stride=(1, 1), groups=10, bias=False)\n",
              "          (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=80, out_features=5, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=5, out_features=80, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): GhostBottleneck(\n",
              "      (conv1): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(20, 40, kernel_size=(1, 1), stride=(1, 1), groups=20, bias=False)\n",
              "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=80, out_features=5, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=5, out_features=80, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): GhostBottleneck(\n",
              "      (conv1): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(20, 40, kernel_size=(1, 1), stride=(1, 1), groups=20, bias=False)\n",
              "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=80, out_features=5, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=5, out_features=80, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage5): Sequential(\n",
              "    (0): GhostBottleneck(\n",
              "      (conv1): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(20, 40, kernel_size=(1, 1), stride=(1, 1), groups=20, bias=False)\n",
              "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(40, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=96, out_features=6, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=6, out_features=96, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): GhostBottleneck(\n",
              "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), groups=24, bias=False)\n",
              "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=96, out_features=6, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=6, out_features=96, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage6): Sequential(\n",
              "    (0): GhostBottleneck(\n",
              "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), groups=24, bias=False)\n",
              "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=192, out_features=12, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=12, out_features=192, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): GhostBottleneck(\n",
              "      (conv1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), groups=48, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=192, out_features=12, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=12, out_features=192, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): GhostBottleneck(\n",
              "      (conv1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), groups=48, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=192, out_features=12, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=12, out_features=192, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): GhostBottleneck(\n",
              "      (conv1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), groups=48, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=192, out_features=12, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=12, out_features=192, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage7): Sequential(\n",
              "    (0): GhostBottleneck(\n",
              "      (conv1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (ghost): GhostModule(\n",
              "        (primary_conv): Sequential(\n",
              "          (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (cheap_operation): Sequential(\n",
              "          (0): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), groups=48, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (conv2): Conv2d(96, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (se): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=320, out_features=20, bias=True)\n",
              "          (1): ReLU(inplace=True)\n",
              "          (2): Linear(in_features=20, out_features=320, bias=True)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv9): Sequential(\n",
              "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=1280, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load GhostNet model\n",
        "num_epochs = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ghostnet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEs75psr-vOg"
      },
      "outputs": [],
      "source": [
        "log_file_path = \"/content/gdrive/MyDrive/Project_II/model_logging/ghost_net_V2_mnist.log\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoEBUvaO496s",
        "outputId": "cf846c1c-55b7-402a-8081-b9c20f65167b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: File log contains incomplete or invalid information.\n"
          ]
        }
      ],
      "source": [
        "# Read the information from the log file and continue the training loop from the neareast completed epoch.\n",
        "num_epochs_completed, last_epoch_info = read_log(log_file_path)\n",
        "start_epoch = num_epochs_completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UIita3X-vr1",
        "outputId": "a9dcf662-f94f-4ada-eac9-e2fb4931100e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 2:\n",
            "\tLoss: 0.524, Accuracy: 82.31%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 3:\n",
            "\tLoss: 0.516, Accuracy: 82.51%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 4:\n",
            "\tLoss: 0.504, Accuracy: 83.01%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 5:\n",
            "\tLoss: 0.497, Accuracy: 83.26%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 6:\n",
            "\tLoss: 0.493, Accuracy: 83.35%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 7:\n",
            "\tLoss: 0.485, Accuracy: 83.69%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 8:\n",
            "\tLoss: 0.481, Accuracy: 83.82%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 9:\n",
            "\tLoss: 0.478, Accuracy: 83.85%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 10:\n",
            "\tLoss: 0.470, Accuracy: 84.11%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 11:\n",
            "\tLoss: 0.471, Accuracy: 84.03%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 12:\n",
            "\tLoss: 0.467, Accuracy: 84.08%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 13:\n",
            "\tLoss: 0.466, Accuracy: 84.47%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 14:\n",
            "\tLoss: 0.464, Accuracy: 84.36%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 15:\n",
            "\tLoss: 0.459, Accuracy: 84.52%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 16:\n",
            "\tLoss: 0.455, Accuracy: 84.91%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 17:\n",
            "\tLoss: 0.454, Accuracy: 84.93%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 18:\n",
            "\tLoss: 0.446, Accuracy: 85.29%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 19:\n",
            "\tLoss: 0.446, Accuracy: 85.14%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 20:\n",
            "\tLoss: 0.439, Accuracy: 85.25%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 21:\n",
            "\tLoss: 0.443, Accuracy: 85.29%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 22:\n",
            "\tLoss: 0.436, Accuracy: 85.39%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 23:\n",
            "\tLoss: 0.436, Accuracy: 85.42%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 24:\n",
            "\tLoss: 0.434, Accuracy: 85.55%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 25:\n",
            "\tLoss: 0.435, Accuracy: 85.43%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 26:\n",
            "\tLoss: 0.427, Accuracy: 85.76%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 27:\n",
            "\tLoss: 0.425, Accuracy: 85.94%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 28:\n",
            "\tLoss: 0.430, Accuracy: 85.67%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 29:\n",
            "\tLoss: 0.422, Accuracy: 85.95%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 30:\n",
            "\tLoss: 0.416, Accuracy: 86.07%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 31:\n",
            "\tLoss: 0.413, Accuracy: 86.31%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 32:\n",
            "\tLoss: 0.409, Accuracy: 86.52%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 33:\n",
            "\tLoss: 0.411, Accuracy: 86.36%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 34:\n",
            "\tLoss: 0.405, Accuracy: 86.64%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 35:\n",
            "\tLoss: 0.402, Accuracy: 86.74%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 36:\n",
            "\tLoss: 0.402, Accuracy: 86.75%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 37:\n",
            "\tLoss: 0.398, Accuracy: 86.76%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 38:\n",
            "\tLoss: 0.394, Accuracy: 86.92%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 39:\n",
            "\tLoss: 0.393, Accuracy: 86.82%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 40:\n",
            "\tLoss: 0.393, Accuracy: 86.98%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 41:\n",
            "\tLoss: 0.396, Accuracy: 86.77%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 42:\n",
            "\tLoss: 0.390, Accuracy: 87.31%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 43:\n",
            "\tLoss: 0.388, Accuracy: 87.17%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 44:\n",
            "\tLoss: 0.389, Accuracy: 87.05%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 45:\n",
            "\tLoss: 0.385, Accuracy: 87.17%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 46:\n",
            "\tLoss: 0.385, Accuracy: 87.20%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 47:\n",
            "\tLoss: 0.379, Accuracy: 87.45%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 48:\n",
            "\tLoss: 0.380, Accuracy: 87.47%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 49:\n",
            "\tLoss: 0.379, Accuracy: 87.55%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 50:\n",
            "\tLoss: 0.375, Accuracy: 87.77%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 51:\n",
            "\tLoss: 0.375, Accuracy: 87.59%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 52:\n",
            "\tLoss: 0.380, Accuracy: 87.66%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 53:\n",
            "\tLoss: 0.380, Accuracy: 87.44%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 54:\n",
            "\tLoss: 0.373, Accuracy: 87.78%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 55:\n",
            "\tLoss: 0.374, Accuracy: 87.70%\n",
            "GhostNet V2\n",
            "--------------------------------------------------\n",
            "Epoch 56:\n",
            "\tLoss: 0.368, Accuracy: 87.86%\n"
          ]
        }
      ],
      "source": [
        "train_model(num_epochs, ghostnet, train_loader, test_loader, criterion, optimizer, device, log_file_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
